{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# feed the LDA model into the pyLDAvis instance\n",
    "# lda_viz = gensimvis.prepare(ldamodel, corpus, dictionary)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/dataframes/SDG/all_sdg_fixed_dst.pkl\")\n",
    "df['TXT'] = df['AB'] +\" \"+ df['TI'] +\" \"+ df ['DE']\n",
    "\n",
    "data = df.TXT.values.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'paris', 'agreement', 'success', 'depends', 'on', 'parties', 'implementation', 'of', 'their', 'nationally', 'determined', 'contributions', 'ndcs', 'towards', 'the', 'paris', 'agreement', 'goals', 'in', 'these', 'climate', 'action', 'plans', 'most', 'developing', 'countries', 'make', 'their', 'mitigation', 'and', 'adaptation', 'contributions', 'conditional', 'upon', 'receiving', 'international', 'support', 'finance', 'technology', 'transfer', 'and', 'or', 'capacity', 'building', 'while', 'provision', 'of', 'support', 'for', 'ndc', 'implementation', 'could', 'enhance', 'equity', 'among', 'countries', 'the', 'feasibility', 'of', 'ndc', 'implementation', 'might', 'be', 'challenged', 'by', 'the', 'large', 'number', 'of', 'conditional', 'ndcs', 'this', 'paper', 'addresses', 'the', 'implications', 'of', 'this', 'tension', 'based', 'on', 'an', 'analysis', 'of', 'all', 'ndcs', 'we', 'find', 'that', 'feasibility', 'is', 'challenged', 'because', 'conditions', 'applied', 'to', 'ndcs', 'are', 'often', 'not', 'well', 'defined', 'moreover', 'the', 'costs', 'of', 'implementing', 'all', 'conditional', 'contributions', 'are', 'too', 'high', 'to', 'be', 'covered', 'by', 'existing', 'promises', 'of', 'support', 'from', 'developed', 'countries', 'even', 'if', 'the', 'entire', 'annual', 'billion', 'of', 'climate', 'finance', 'were', 'earmarked', 'for', 'ndc', 'implementation', 'consistent', 'with', 'principles', 'of', 'equity', 'and', 'the', 'prioritization', 'in', 'the', 'paris', 'agreement', 'higher', 'proportion', 'of', 'least', 'developed', 'countries', 'ldcs', 'and', 'small', 'island', 'developing', 'states', 'sids', 'have', 'conditional', 'ndcs', 'than', 'do', 'other', 'countries', 'however', 'differences', 'between', 'the', 'distribution', 'of', 'countries', 'requesting', 'support', 'and', 'those', 'currently', 'receiving', 'support', 'in', 'particular', 'among', 'middle', 'income', 'countries', 'demonstrates', 'potential', 'tensions', 'between', 'feasibility', 'and', 'equity', 'the', 'article', 'concludes', 'with', 'recommendations', 'on', 'how', 'cost', 'estimates', 'and', 'updated', 'ndcs', 'can', 'be', 'strengthened', 'to', 'ensure', 'support', 'for', 'ndc', 'implementation', 'is', 'targeted', 'more', 'equitably', 'and', 'cost', 'effectively', 'key', 'policy', 'insights', 'support', 'requested', 'by', 'developing', 'countries', 'to', 'implement', 'conditional', 'ndcs', 'far', 'exceeds', 'existing', 'funding', 'pledges', 'differences', 'between', 'existing', 'patterns', 'of', 'financial', 'assistance', 'and', 'those', 'implied', 'by', 'requests', 'under', 'conditional', 'ndcs', 'mean', 'that', 'supporting', 'ndcs', 'may', 'require', 'significant', 'shift', 'in', 'provider', 'countries', 'priorities', 'for', 'allocating', 'climate', 'finance', 'this', 'may', 'challenge', 'feasibility', 'the', 'paris', 'agreement', 'provisions', 'on', 'prioritizing', 'ldcs', 'and', 'sids', 'offer', 'valuable', 'guidance', 'in', 'making', 'difficult', 'choices', 'on', 'allocating', 'support', 'to', 'increase', 'the', 'likelihood', 'of', 'attracting', 'support', 'developing', 'countries', 'assisted', 'by', 'capacity', 'building', 'as', 'needed', 'should', 'include', 'credible', 'cost', 'estimates', 'in', 'future', 'ndcs', 'and', 'formulate', 'investment', 'plans', 'by', 'outlining', 'plans', 'to', 'mobilize', 'support', 'in', 'their', 'ndcs', 'developed', 'countries', 'can', 'reassure', 'developing', 'countries', 'that', 'raising', 'the', 'ambition', 'of', 'ndcs', 'is', 'feasible', 'conditional', 'nationally', 'determined', 'contributions', 'in', 'the', 'paris', 'agreement', 'foothold', 'for', 'equity', 'or', 'achilles', 'heel', 'nationally', 'determined', 'contributions', 'unfccc', 'climate', 'finance', 'capacity', 'building', 'technology', 'transfer', 'equity']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield gensim.utils.simple_preprocess(str(sentence), deacc=True)  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'paris_agreement', 'success', 'depends_on', 'parties', 'implementation', 'of', 'their', 'nationally_determined_contributions_ndcs', 'towards', 'the', 'paris_agreement_goals', 'in', 'these', 'climate', 'action_plans', 'most', 'developing_countries', 'make', 'their', 'mitigation', 'and', 'adaptation', 'contributions', 'conditional_upon', 'receiving', 'international', 'support', 'finance', 'technology_transfer', 'and', 'or', 'capacity_building', 'while', 'provision', 'of', 'support', 'for', 'ndc', 'implementation', 'could', 'enhance', 'equity', 'among', 'countries', 'the', 'feasibility', 'of', 'ndc', 'implementation', 'might_be', 'challenged', 'by', 'the', 'large_number', 'of', 'conditional_ndcs', 'this_paper', 'addresses', 'the', 'implications', 'of', 'this', 'tension', 'based', 'on', 'an', 'analysis', 'of', 'all', 'ndcs', 'we_find', 'that', 'feasibility', 'is', 'challenged', 'because', 'conditions', 'applied', 'to', 'ndcs', 'are', 'often', 'not', 'well', 'defined', 'moreover', 'the', 'costs', 'of', 'implementing', 'all', 'conditional', 'contributions', 'are', 'too', 'high', 'to', 'be', 'covered', 'by', 'existing', 'promises', 'of', 'support', 'from', 'developed_countries', 'even_if', 'the', 'entire', 'annual', 'billion', 'of', 'climate', 'finance', 'were', 'earmarked', 'for', 'ndc', 'implementation', 'consistent', 'with', 'principles', 'of', 'equity', 'and', 'the', 'prioritization', 'in', 'the', 'paris_agreement', 'higher', 'proportion', 'of', 'least_developed', 'countries_ldcs', 'and', 'small_island', 'developing_states_sids', 'have', 'conditional_ndcs', 'than', 'do', 'other', 'countries', 'however', 'differences_between', 'the', 'distribution', 'of', 'countries', 'requesting', 'support', 'and', 'those', 'currently', 'receiving', 'support', 'in', 'particular', 'among', 'middle_income_countries', 'demonstrates', 'potential', 'tensions_between', 'feasibility', 'and', 'equity', 'the', 'article_concludes', 'with', 'recommendations', 'on', 'how', 'cost', 'estimates', 'and', 'updated', 'ndcs', 'can_be', 'strengthened', 'to', 'ensure', 'support', 'for', 'ndc', 'implementation', 'is', 'targeted', 'more', 'equitably', 'and', 'cost', 'effectively', 'key', 'policy', 'insights', 'support', 'requested', 'by', 'developing_countries', 'to', 'implement', 'conditional_ndcs', 'far_exceeds', 'existing', 'funding', 'pledges', 'differences_between', 'existing', 'patterns', 'of', 'financial_assistance', 'and', 'those', 'implied', 'by', 'requests', 'under', 'conditional_ndcs', 'mean', 'that', 'supporting', 'ndcs', 'may', 'require', 'significant', 'shift', 'in', 'provider', 'countries', 'priorities', 'for', 'allocating', 'climate', 'finance', 'this', 'may', 'challenge', 'feasibility', 'the', 'paris_agreement', 'provisions', 'on', 'prioritizing', 'ldcs', 'and', 'sids', 'offer_valuable', 'guidance', 'in', 'making', 'difficult', 'choices', 'on', 'allocating', 'support', 'to', 'increase', 'the', 'likelihood', 'of', 'attracting', 'support', 'developing_countries', 'assisted', 'by', 'capacity_building', 'as', 'needed', 'should_include', 'credible', 'cost', 'estimates', 'in', 'future', 'ndcs', 'and', 'formulate', 'investment', 'plans', 'by', 'outlining', 'plans', 'to', 'mobilize', 'support', 'in', 'their', 'ndcs', 'developed_countries', 'can', 'reassure', 'developing_countries', 'that', 'raising', 'the', 'ambition', 'of', 'ndcs', 'is', 'feasible', 'conditional', 'nationally_determined_contributions', 'in', 'the', 'paris_agreement', 'foothold', 'for', 'equity', 'or', 'achilles_heel', 'nationally_determined_contributions', 'unfccc', 'climate', 'finance', 'capacity_building', 'technology_transfer', 'equity']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=10)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n",
      "466\n"
     ]
    }
   ],
   "source": [
    "# spacy stopwords\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "all_stopwords = sp.Defaults.stop_words\n",
    "print(len(all_stopwords))\n",
    "all_stopwords.update([\"technology\", \"use\",\"uses\", \"used\", \"model\", \"models\", \"system\",\"systems\", \"base\",\"based\",\"bases\", \"high\", \"index\",\"approach\",\n",
    "                      \"information\", \"datum\", \"basis\", \"process\", \"tool\",\"new\", \"problem\", \"result\", \"results\", \"resource\",\n",
    "                      \"method\", \"image\", \"study\", \"feature\", \"technique\", \"different\", \"test\", \"low\", \"low\", \"class\", \"analysis\",\n",
    "                      \"paper\", \"provide\", \"provides\", \"provided\", \"data\", \"increase\", \"increases\", \"increased\", \"propose\", \"proposes\",\n",
    "                     \"proposed\", \"feature\", \"features\", \"big\", \"level\", 'object', \"levels\", \"objects\", \"method\",\"methods\",\n",
    "                     \"modelled\", \"modeled\", \"modelling\", \"modeling\", \"large\", \"case\", \"cases\", \"present\", \"presents\", \"consider\",\n",
    "                     \"considering\", \"considered\", \"prediction\", \"predicts\", \"predict\", \"predicted\", \"compare\", \"compares\", \"compared\",\n",
    "                     \"comparing\", \"improve\", \"improves\", \"improving\", \"improved\", \"estimate\", \"estimating\", \"estimates\", \"estimated\",\n",
    "                     \"network\", \"networks\", \"control\", \"controls\", \"controlled\", \"controlling\", \"include\", \"includes\", \"including\",\n",
    "                     \"included\", \"show\", \"shows\", \"showed\", \"showing\", \"important\", \"high\", \"develop\", \"develops\", \"developed\", \"developing\",\n",
    "                     \"change\", \"changes\", \"changed\", \"changing\", \"performance\", \"apply\", \"applies\", \"applied\", \"applying\",\n",
    "                     \"observe\", \"observes\", \"observing\", \"observed\", \"lean\", \"learns\", \"learned\", \"value\", \"obtain\", \"obtained\",\n",
    "                     \"obtains\", \"obtained\", \"indicate\", \"indicates\", \"indicating\",\"indicated\", \"application\", \"applications\", \"reduce\", \"time\", \"design\", \"research\", \"management\"])\n",
    "print(len(all_stopwords))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in all_stopwords] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['paris_agreement', 'success', 'depend', 'party', 'implementation', 'paris_agreement_goal', 'climate', 'action_plan', 'country', 'mitigation', 'adaptation', 'contribution', 'conditional', 'receive', 'international', 'support', 'finance', 'transfer', 'capacity_builde', 'provision', 'support', 'ndc', 'implementation', 'enhance', 'equity', 'country', 'implementation', 'challenge', 'number', 'conditional_ndcs', 'address', 'implication', 'tension', 'ndcs', 'find', 'feasibility', 'challenge', 'condition', 'ndcs', 'define', 'cost', 'implement', 'conditional', 'contribution', 'cover', 'exist', 'promise', 'support', 'country', 'entire', 'annual', 'climate', 'finance', 'earmark', 'implementation', 'consistent', 'principle', 'equity', 'prioritization', 'paris_agreement', 'high', 'proportion', 'small_island', 'states_sid', 'conditional_ndcs', 'country', 'difference', 'distribution', 'country', 'request', 'support', 'currently', 'receive', 'support', 'particular', 'middle_income_countrie', 'demonstrate', 'potential', 'tension', 'feasibility', 'equity', 'article_conclude', 'recommendation', 'cost', 'update', 'ndcs', 'strengthen', 'ensure', 'support', 'ndc', 'implementation', 'target', 'equitably', 'cost', 'effectively', 'key', 'policy', 'insight', 'support', 'request', 'country', 'implement', 'far_exceed', 'exist', 'funding', 'pledge', 'difference', 'exist', 'pattern', 'financial_assistance', 'imply', 'request', 'conditional_ndcs', 'mean', 'support', 'ndcs', 'require', 'significant', 'shift', 'provider', 'country', 'priority', 'allocate', 'climate', 'finance', 'challenge', 'feasibility', 'paris_agreement', 'provision', 'prioritize', 'ldcs', 'sid', 'guidance', 'make', 'difficult', 'choice', 'allocate', 'support', 'likelihood', 'attract', 'support', 'country', 'assist', 'capacity_builde', 'need', 'credible', 'cost', 'future', 'ndcs', 'formulate', 'investment', 'plan', 'outline', 'plan', 'mobilize', 'support', 'country', 'reassure', 'country', 'raise', 'ambition', 'ndc', 'feasible', 'conditional', 'paris_agreement', 'foothold', 'equity', 'climate', 'finance', 'capacity_builde', 'transfer', 'equity']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "data_words_trigrams = make_trigrams(data_words_nostops)\n",
    "\n",
    "\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_trigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "# print(corpus[:1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_stopwords.update(\n",
    "    {\"rights_reserve\", \"decision_make\", \"decision_maker\", \"principal_component\", \"recent_year\", \"spatial_revolution\",\n",
    "     \"authors_publishe\", \"classification_accuracy\"}\n",
    ")\n",
    "all_stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "frequencies = Counter()\n",
    "frequencies_ngram = Counter()\n",
    "stuff = [[(id2word[id], freq) for id, freq in cp] for cp in corpus]\n",
    "for i, tok in enumerate(stuff):\n",
    "    for tup in tok:\n",
    "        if tup[0] not in all_stopwords:\n",
    "            if \"_\" in tup[0]:\n",
    "                frequencies_ngram[tup[0]] += 1\n",
    "            frequencies[tup[0]] +=1\n",
    "\n",
    "\n",
    "print(frequencies_ngram.most_common(10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Nuage de mots\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=100, scale=2)\n",
    "wordcloud.generate_from_frequencies(frequencies_ngram)\n",
    "\n",
    "wordcloud.to_file(\"../img/worldcloud_sdg.png\", )\n",
    "wordcloud.to_image()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Nuage de mots\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=100)\n",
    "wordcloud.generate_from_frequencies(frequencies)\n",
    "wordcloud.to_image()\n",
    "# wordcloud.to_file(\"img/worldcloud.png\")\n",
    "wordcloud.to_image()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
