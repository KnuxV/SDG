{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import itertools\n",
    "import tqdm\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                                              Query  \\\n0     1.1                                            poverty   \n1     1.1                                    poverty line\\w*   \n2     1.1                                  poverty indicator   \n3     1.1                                            poverty   \n4     1.1                                             income   \n5     1.1                                            poverty   \n6     1.2                                            poverty   \n7     1.3  social protection|economic marginalization|eco...   \n8     1.4                                    access|right\\w*   \n9     1.4                                       ownership\\w*   \n10    1.5                                        resilien\\w*   \n11    1.5                                        disaster\\w*   \n12    1.5                                        disaster\\w*   \n13    1.5                                        disaster\\w*   \n14    1.a                                            poverty   \n15    1.a                                            poverty   \n16    1.a                                      government\\w*   \n17    1.a                          government\\w* expenditure   \n18    1.b                                         investment   \n19    1.b                                      government\\w*   \n20    1.b                          government\\w* expenditure   \n\n                                                 Near  \\\n0         eradicat\\w*|reduc\\w*|end|ending|alleviat\\w*   \n1                                                 NaN   \n2                                                 NaN   \n3                                        inequalit\\w*   \n4                                        inequalit\\w*   \n5                                  chronic\\w*|extreme   \n6   living|life|child\\w*|socioeconomic\\w*|socio-ec...   \n7                                      poverty|income   \n8              economic resource\\w*| basic service\\w*   \n9                                                land   \n10                                poverty|the poor\\w*   \n11                                 number of death\\w*   \n12                                   economic loss\\w*   \n13                                  risk reduction\\w*   \n14                                         develop\\w*   \n15                                         develop\\w*   \n16                                        spending\\w*   \n17           education\\w*|health\\w*|social protection   \n18                                            poverty   \n19                                        spending\\w*   \n20                          women|poor and vulnerable   \n\n                                      Near.1  \n0                                        NaN  \n1                                        NaN  \n2                                        NaN  \n3                                        NaN  \n4                                        NaN  \n5                                        NaN  \n6                                        NaN  \n7                                        NaN  \n8                                        NaN  \n9                                        NaN  \n10                                       NaN  \n11                                       NaN  \n12                                       NaN  \n13                                strateg\\w*  \n14                   cooperat\\w*|assistan\\w*  \n15                       program\\w*|polic\\w*  \n16  education\\w*|health\\w*|social protection  \n17                                       NaN  \n18                                       NaN  \n19                 women|poor and vulnerable  \n20                                       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Query</th>\n      <th>Near</th>\n      <th>Near.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.1</td>\n      <td>poverty</td>\n      <td>eradicat\\w*|reduc\\w*|end|ending|alleviat\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.1</td>\n      <td>poverty line\\w*</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.1</td>\n      <td>poverty indicator</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.1</td>\n      <td>poverty</td>\n      <td>inequalit\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.1</td>\n      <td>income</td>\n      <td>inequalit\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.1</td>\n      <td>poverty</td>\n      <td>chronic\\w*|extreme</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.2</td>\n      <td>poverty</td>\n      <td>living|life|child\\w*|socioeconomic\\w*|socio-ec...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.3</td>\n      <td>social protection|economic marginalization|eco...</td>\n      <td>poverty|income</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.4</td>\n      <td>access|right\\w*</td>\n      <td>economic resource\\w*| basic service\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.4</td>\n      <td>ownership\\w*</td>\n      <td>land</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.5</td>\n      <td>resilien\\w*</td>\n      <td>poverty|the poor\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.5</td>\n      <td>disaster\\w*</td>\n      <td>number of death\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.5</td>\n      <td>disaster\\w*</td>\n      <td>economic loss\\w*</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.5</td>\n      <td>disaster\\w*</td>\n      <td>risk reduction\\w*</td>\n      <td>strateg\\w*</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.a</td>\n      <td>poverty</td>\n      <td>develop\\w*</td>\n      <td>cooperat\\w*|assistan\\w*</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.a</td>\n      <td>poverty</td>\n      <td>develop\\w*</td>\n      <td>program\\w*|polic\\w*</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.a</td>\n      <td>government\\w*</td>\n      <td>spending\\w*</td>\n      <td>education\\w*|health\\w*|social protection</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.a</td>\n      <td>government\\w* expenditure</td>\n      <td>education\\w*|health\\w*|social protection</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.b</td>\n      <td>investment</td>\n      <td>poverty</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.b</td>\n      <td>government\\w*</td>\n      <td>spending\\w*</td>\n      <td>women|poor and vulnerable</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1.b</td>\n      <td>government\\w* expenditure</td>\n      <td>women|poor and vulnerable</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../query/query copy.ods\", engine=\"odf\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def fix_length(lst, length):\n",
    "    return (lst + [None] * length)[:length]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from pyexcel_ods import get_data\n",
    "import json\n",
    "query_file = \"../query/query copy.ods\"\n",
    "excel_file = get_data(query_file)\n",
    "lst = []\n",
    "for sdg_number, sdg  in excel_file.items():\n",
    "    for ind, line in enumerate(sdg):\n",
    "        line = fix_length(line, 5)\n",
    "        if ind == 0:\n",
    "            continue\n",
    "        # target, main_query, near_1, near_2, not_1 = line\n",
    "        target, *query, not_1 = line\n",
    "        query = [elem for elem in query if elem is not None]\n",
    "\n",
    "\n",
    "        for chunk in itertools.permutations(query, len(query)):\n",
    "            chunk = [\"(\"+str(elem)+\")\" for elem in chunk]\n",
    "            new_line = [sdg_number, target, '\\W+(?:\\w+\\W+){0,3}?'.join(chunk), not_1]\n",
    "            lst.append(new_line)\n",
    "\n",
    "\n",
    "df_query = pd.DataFrame(data=lst, columns=['SDG', 'Target', 'Query', 'Not'])\n",
    "df_query.to_pickle(\"../query/query.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/dataframes/SDG/intersection_sdg_dt.pkl\")\n",
    "df['TXT'] = df['AB'] + \" \" + df['TI'] + \" \" + df['DE']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def to_raw(string):\n",
    "    return fr\"{string.strip()}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart sustainable/sustainable smart cities, a defining context for ICT for sustainability, have recently become the leading global paradigm of urbanism. With this position, they are increasingly gaining traction and prevalence worldwide as a promising response to the mounting challenges of sustainability and the potential effects of urbanization. In the meantime, the research in this area is garnering growing attention and rapidly burgeoning, and its status is consolidating as one of the most enticing areas of investigation today. A large part of research in this area focuses on exploiting the potentials and opportunities of advanced technologies and their novel applications, especially big data computing, as an effective way to mitigate or overcome the issue of sustainable cities and smart cities being extremely fragmented as landscapes and weakly connected as approaches. In this context, one of the most appealing strands of research in the domain of smart sustainable urbanism is that which is concerned with futures studies related to the planning and development of new models for smart sustainable cities. Not only in the futures studies using a backcasting approach to strategic planning and development, but also in those using other approaches, is trend analysis a necessary step to perform and a critical input to the scenario analysis as part of such studies. With that in regard, this chapter aims to provide a detailed qualitative analysis of the key forms of trends shaping and driving the emergence, materialization, and evolvement of the phenomenon of smart sustainable cities as a leading paradigm of urbanism, as well as to identify the relevant expected developments related to smart sustainable urbanism. It is more likely that these forms of trends reflect a congeries of long-lasting forces behind the continuation of smart sustainable cities as a set of multiple approaches to, and multiple pathways to achieving, smart sustainable urban development. As part of the futures studies related to smart sustainable city planning and development using a backcasting methodology, both the trends and expected developments are key ingredients of, and crucial inputs for, analyzing different alternative scenarios for the future or long-term visions pertaining to desirable sustainable futures in terms of their opportunities, potentials, environmental and social benefits, and other effects. This study serves to provide a necessary material for scholars, researchers, and academics, as well as other futurists, who are in the process of conducting, or planning to carry out, futures research projects or scholarly backcasting endeavors related to the field of smart sustainable urbanism. Sustainable, Smart, and Data-Driven Approaches to Urbanism and their Integrative Aspects: A Qualitative Analysis of Long-Lasting Trends Smart sustainable/sustainable smart cities; Sustainable cities; Smart cities; Smarter cities; Big data computing; Sustainability; Sustainable development; Trends; Futures studies; Backcasting\n",
      "11.3 (sustainab\\w*|inclusi\\w*)\\W+(?:\\w+\\W+){0,3}?(urbanisation|urbanization|settlement\\w*|city|cities)\n",
      "<re.Match object; span=(6, 42), match='sustainable/sustainable smart cities'>\n",
      "11.a (city|cities|urban|regional|national)\\W+(?:\\w+\\W+){0,3}?(plan\\w*)\\W+(?:\\w+\\W+){0,3}?(development)\n",
      "<re.Match object; span=(2047, 2076), match='city planning and development'>\n"
     ]
    }
   ],
   "source": [
    "txt = df.sample().TXT.iloc[0]\n",
    "print(txt)\n",
    "for ind, row in df_query.iterrows():\n",
    "    if not row['Not']:\n",
    "        try:\n",
    "            m = re.search(to_raw(row['Query']), txt)\n",
    "        except:\n",
    "            print(\"error, weird query\")\n",
    "        if m:\n",
    "            print(row['Target'], row['Query'])\n",
    "            print(m)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../query/regex/SDG-14_life_below_water.txt\n",
      "here\n",
      "../query/regex/SDG-17_partnerships_for_the_goals.txt\n",
      "here\n",
      "../query/regex/SDG-07_affordable_and_clean_energy.txt\n",
      "here\n",
      "../query/regex/SDG-15_life_on_land.txt\n",
      "((sustainab\\w*|conserv\\w*|restor\\w*) NEAR/3 (ecosyst\\w*|terrestrial|freshwater|inland|forest\\w*|rainforest\\w*|agroforest\\w*|deforest\\w*|reforest\\w*|afforest\\w*|environment\\w*|soil|land))  \n",
      "(poaching|trafficking) (species|flora|fauna|wildlife)  \n",
      "(invas\\w*) NEAR/3 (alien|nonnative|non-native|nonindigenous|non-indigenous) NEAR/3 (species|animal\\w*|plant\\w*)  \n",
      "(protect\\w*) NEAR/3 (threaten\\w*|endanger\\w*) NEAR/3 (species|animal\\w*|plant\\w*)  \n",
      "((prevent\\w*) NEAR/3 (extinct\\w*)) ((threaten\\w*|endanger\\w*) NEAR/3 (species|animal\\w*|plant\\w*))  \n",
      "((ecosystem NEAR/3 biodiversity)|species diversity) (polic\\w*|strateg\\w*|plan|plans|planning)  \n",
      "(poaching|trafficking) (species|flora|fauna|wildlife)  \n",
      "here\n",
      "../query/regex/SDG-04_quality_education.txt\n",
      "here\n",
      "../query/regex/SDG-02_zero_hunger.txt\n",
      "here\n",
      "../query/regex/SDG-08_decent_work_and_economic_growth.txt\n",
      "here\n",
      "../query/regex/SDG-06_clean_water_and_sanitation.txt\n",
      "here\n",
      "../query/regex/SDG-11_sustainable_cities_and_communities.txt\n",
      "here\n",
      "../query/regex/SDG-05_gender_equality.txt\n",
      "here\n",
      "../query/regex/SDG-01_no_poverty.txt\n",
      "here\n",
      "../query/regex/SDG-10_reduce_inequalities.txt\n",
      "here\n",
      "../query/regex/SDG-12_responsible_consumption_and_production.txt\n",
      "here\n",
      "../query/regex/SDG-09_industry,_innovation_and_infrastructure.txt\n",
      "here\n",
      "../query/regex/SDG-03_good_health_and_well-being.txt\n",
      "here\n",
      "../query/regex/SDG-13_climate_action.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [00:32<00:04,  2.19s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m itertools\u001B[38;5;241m.\u001B[39mpermutations(line_as_list, \u001B[38;5;28mlen\u001B[39m(line_as_list)):\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;66;03m# print('\\W+(?:\\w+\\W+){0,3}?'.join(chunk))\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m         line \u001B[38;5;241m=\u001B[39m line \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mW+(?:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mW+)\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m0,3}?\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(chunk)\n\u001B[1;32m     25\u001B[0m     lst\u001B[38;5;241m.\u001B[39mappend(line[\u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNEAR/6\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m line:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "directory = glob.glob(\"../query/regex_query/*\")\n",
    "for path in tqdm.tqdm(directory):\n",
    "    ending = path.split(\"/\")[-1]\n",
    "    new_path = \"../query/regex/\" + ending\n",
    "    print(new_path)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lst = []\n",
    "        for line in f:\n",
    "            reg = re.compile(r'TS = \\((.+)\\)(OR)?')\n",
    "            m = re.search(pattern=reg, string=line)\n",
    "            if m:\n",
    "                line = m.group(1).strip()\n",
    "                line = line.replace(\"\\\"\", \"\").replace(\"*\", \"\\w*\").replace(\" AND \", \" \").replace(\"OR\", \"|\").replace(\" )\", \")\").replace(\"( \", \"(\").replace(\" | \", \"|\")\n",
    "                if \"NOT\" in line:\n",
    "                    line_pos, line_neg = line.split(\"NOT\")\n",
    "                    print(line_pos)\n",
    "                    line = line_pos.strip()\n",
    "                if \"NEAR/3\" in line:\n",
    "                    line_as_list = line.split(\"NEAR/3\")\n",
    "                    line_as_list = [elem.strip() for elem in line_as_list]\n",
    "                    line = \"\"\n",
    "                    for chunk in itertools.permutations(line_as_list, len(line_as_list)):\n",
    "                        # print('\\W+(?:\\w+\\W+){0,3}?'.join(chunk))\n",
    "                        line = line + \"|\" + '\\W+(?:\\w+\\W+){0,3}?'.join(chunk)\n",
    "                    lst.append(line[1:]+\"\\n\")\n",
    "                if \"NEAR/6\" in line:\n",
    "                    line_as_list = line.split(\"NEAR/3\")\n",
    "                    line_as_list = [elem.strip() for elem in line_as_list]\n",
    "                    line = \"\"\n",
    "                    for chunk in itertools.permutations(line_as_list, len(line_as_list)):\n",
    "                        line = line + \"|\" + '\\W+(?:\\w+\\W+){0,6}?'.join(chunk)\n",
    "                    lst.append(line[1:]+\"\\n\")\n",
    "    # with open(new_path, 'w', encoding='utf-8') as w:\n",
    "    #     print(\"here\")\n",
    "    #     w.writelines(lst)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(investment)\\W+(?:\\w+\\W+){0,3}?(poverty)|(poverty)\\W+(?:\\w+\\W+){0,3}?(investment)\n",
      "(poverty)\\W+(?:\\w+\\W+){0,3}?(eradicat\\w*|reduc\\w*|end|ending|alleviat\\w*)|(eradicat\\w*|reduc\\w*|end|ending|alleviat\\w*)\\W+(?:\\w+\\W+){0,3}?(poverty)\n",
      "(poverty)\\W+(?:\\w+\\W+){0,3}?(develop\\w*)\\W+(?:\\w+\\W+){0,3}?(cooperat\\w*|assistan\\w*)|(poverty)\\W+(?:\\w+\\W+){0,3}?(cooperat\\w*|assistan\\w*)\\W+(?:\\w+\\W+){0,3}?(develop\\w*)|(develop\\w*)\\W+(?:\\w+\\W+){0,3}?(poverty)\\W+(?:\\w+\\W+){0,3}?(cooperat\\w*|assistan\\w*)|(develop\\w*)\\W+(?:\\w+\\W+){0,3}?(cooperat\\w*|assistan\\w*)\\W+(?:\\w+\\W+){0,3}?(poverty)|(cooperat\\w*|assistan\\w*)\\W+(?:\\w+\\W+){0,3}?(poverty)\\W+(?:\\w+\\W+){0,3}?(develop\\w*)|(cooperat\\w*|assistan\\w*)\\W+(?:\\w+\\W+){0,3}?(develop\\w*)\\W+(?:\\w+\\W+){0,3}?(poverty)\n"
     ]
    }
   ],
   "source": [
    "# TEST NEAR interchangeable\n",
    "directory = glob.glob(\"../query/regex_query/test.txt\")\n",
    "with open(\"../query/regex_query/test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lst = []\n",
    "    for line in f:\n",
    "        reg = re.compile(r'TS = \\((.+)\\)(OR)?')\n",
    "        m = re.search(pattern=reg, string=line)\n",
    "        if m:\n",
    "            line = m.group(1).strip()\n",
    "            line = line.replace(\"\\\"\", \"\").replace(\"*\", \"\\w*\").replace(\" AND \", \" \").replace(\"OR\", \"|\").replace(\" )\", \")\").replace(\"( \", \"(\").replace(\" | \", \"|\")\n",
    "            if \"NOT\" in line:\n",
    "                line_pos, line_neg = line.split(\"NOT\")\n",
    "                line = line_pos.strip()\n",
    "            if \"NEAR/3\" in line:\n",
    "                line_as_list = line.split(\"NEAR/3\")\n",
    "                line_as_list = [elem.strip() for elem in line_as_list]\n",
    "                line_near = \"\"\n",
    "                for chunk in itertools.permutations(line_as_list, len(line_as_list)):\n",
    "                    # print('\\W+(?:\\w+\\W+){0,3}?'.join(chunk))\n",
    "                    line_near = line_near + \"|\" + '\\W+(?:\\w+\\W+){0,3}?'.join(chunk)\n",
    "                print(line_near[1:])\n",
    "                lst.append(line_near[1:]+\"\\n\")\n",
    "with open(\"../query/regex_query/test_reg.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(lst)\n",
    "        # .replace(' NEAR/3 ', '\\W+(?:\\w+\\W+){0,3}?').replace(' NEAR/6 ', '\\W+(?:\\w+\\W+){0,6}?')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG-07_affordable_and_clean_energy\n",
      "((reduc\\w*)\\W+(?:\\w+\\W+){0,3}?(energy consumption))\n",
      "\n",
      "reducing the energy consumption\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('SDG-07_affordable_and_clean_energy', 'reducing the energy consumption')]"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = glob.glob(\"../query/regex_query/regex/*\")\n",
    "def to_raw(string):\n",
    "    return fr\"{string.strip()}\"\n",
    "def check_for_sdg(txt):\n",
    "    res = []\n",
    "    for path in directory:\n",
    "        ending = path.split(\"/\")[-1][:-4]\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                reg = re.compile(to_raw(line))\n",
    "\n",
    "                m = re.search(reg, txt)\n",
    "                if m:\n",
    "                    print(ending)\n",
    "                    print(line)\n",
    "                    print(m.group())\n",
    "                    res.append((ending, m.group()))\n",
    "    return res\n",
    "\n",
    "txt = \"Wireless sensor networks have been widely used in industrial IoT contexts due to their usefulsupport during the production monitoring and risk pre-warning. However, complicated and extremelyvariable industrial environments call for higher communication stability and reliability toguarantee timely transmission of monitored data. Considering mobile intelligences such as AutomatedGuided Vehicles (AGVs), within industrial scenarios, we propose a solution based on hybrid (fixedand mobile) industrial wireless sensor networks featured with a task-oriented model. The proposalincludes a heuristic modeling method adopted to assign tasks from definite orders which will be sentto the controller, and a collaborative routing algorithm exploiting the AGVs mobility on specifictrajectories. Experiments have shown that, using mobility features of the AGVs, the integratedsolution can promptly repair the network when a node and the relative link fail or the detectedquality is low, significantly reducing the energy consumption of wireless nodes and datacommunication delay, thus improving the overall throughput and reliability of industrial IoTsystems. (C) 2018 Published by Elsevier B.V.\"\n",
    "check_for_sdg(txt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def to_raw(string):\n",
    "    return fr\"{string.strip()}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "development and poverty cooperation\n"
     ]
    }
   ],
   "source": [
    "txt = \"development and poverty cooperation are paramount\"\n",
    "with open(\"../query/regex_query/test_reg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        reg = re.compile(to_raw(line), flags=re.IGNORECASE)\n",
    "        m = re.search(reg, txt)\n",
    "        if m:\n",
    "            print(m.group())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'(\\n\\nTS = (( \"poverty\" ) NEAR/3 ( \"eradicat*\" OR \"reduc*\" OR \"end\" OR \"ending\" OR \"alleviat*\") ) OR\\n\\nTS = ((\"poverty line*\") OR (\"poverty indicator*\") ) OR\\n\\nTS = ((\"poverty\" OR \"income\") NEAR/3 (\"inequalit*\") ) OR\\n\\nTS = ((\"poverty\") NEAR/3 (\"chronic*\" OR \"extreme\") )\\nOR\\n\\nTS = ( ( \"poverty\" ) NEAR/3 ( \"living\" OR \"life\" OR \"child*\" OR \"socioeconomic*\" OR \"socio-economic*\" OR \"social welfare\" OR \"household*\" OR \"income*\" ) OR (\"poverty line*\") )\\nOR\\n\\nTS = ( (\"social protection\" OR \"economic marginalization\" OR \"economic marginalisation\" OR \"poor*\" OR \"vulnerable\") AND (\"poverty\" OR \"income\") )\\nOR\\n\\nTS = ((\"access\" OR \"right*\") NEAR/3 (\"economic resource*\" OR \"basic service*\") ) OR\\n\\nTS = ((\"ownership*\") NEAR/3 (\"land\") )\\nOR\\n\\nTS = ((\"resilien*\") NEAR/3 (\"poverty\" OR \"the poor*\") ) OR\\n\\nTS = ((\"disaster*\") NEAR/3 ( \"number of death*\") ) OR\\n\\nTS = ((\"disaster*\") NEAR/3 ( \"economic loss*\") ) OR\\n\\nTS = ((\"disaster*\") NEAR/3 (\"risk reduction*\") NEAR/3 (\"strateg*\") )\\nOR\\n\\nTS = ((\"poverty\") NEAR/3 (\"develop*\") NEAR/3 (\"cooperat*\" OR \"assistan*\") ) OR\\n\\nTS = ((\"poverty\") NEAR/3 (\"develop*\") NEAR/3 (\"program*\" OR \"polic*\") ) OR\\n\\nTS = ((\"government*\") NEAR/3 (\"spending*\") NEAR/3 (\"education*\" OR \"health*\" OR \"social protection\") ) OR\\n\\nTS = ((\"government* expenditure\") NEAR/3 (\"education*\" OR \"health*\" OR \"social protection\") )\\nOR\\n\\nTS = ((\"investment\") NEAR/3 (\"poverty\") ) OR\\n\\nTS = ((\"government*\") NEAR/3 (\"spending*\") NEAR/3 (\"women\" OR \"poor and vulnerable\") ) OR\\n\\nTS = ((\"government* expenditure\") NEAR/3 (\"women\" OR \"poor and vulnerable\") )\\n)'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "reg = re.compile(r\".*(TS.+)\\)\", flags=re.DOTALL)\n",
    "m = re.search('(?<=abc)def', 'abcdef')\n",
    "g = re.match(pattern=reg, string=txt)\n",
    "g.group()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "reg = r\"poverty eradication\"\n",
    "regg = re.compile(reg)\n",
    "m = re.match(reg, \"poverty eradication is paramount\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'poverty eradication'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_sdg = pd.read_pickle(\"../data/dataframes/SDG/all_sdg_fixed_dst.pkl\")\n",
    "df_inter = df_sdg[df_sdg['DST']]\n",
    "df_dt = pd.read_pickle(\"../data/dataframes/digital/all_digital.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "lst_eu = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Ireland\", \"Italy\",\n",
    "          \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\", \"Poland\",\n",
    "          \"Portugal\", \"Romania\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c_dt = Counter()\n",
    "c_sdg = Counter()\n",
    "c_inter = Counter()\n",
    "\n",
    "\n",
    "for ind, row in df_sdg.iterrows():\n",
    "    lst_country = row.CN.split(\", \")\n",
    "    for c in lst_country:\n",
    "        c_sdg['world'] += 1\n",
    "        if c in [\"United States\", \"China\"]:\n",
    "            c_sdg[c] += 1\n",
    "        if c in lst_eu:\n",
    "            c_sdg['EU'] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "for ind, row in df_dt.iterrows():\n",
    "    lst_country = row.CN.split(\", \")\n",
    "    for c in lst_country:\n",
    "        c_dt['world'] += 1\n",
    "        if c in [\"United States\", \"China\"]:\n",
    "            c_dt[c] += 1\n",
    "        if c in lst_eu:\n",
    "            c_dt['EU'] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "for ind, row in df_inter.iterrows():\n",
    "    lst_country = row.CN.split(\", \")\n",
    "    for c in lst_country:\n",
    "        c_inter['world'] += 1\n",
    "        if c in [\"United States\", \"China\"]:\n",
    "            c_inter[c] += 1\n",
    "        if c in lst_eu:\n",
    "            c_inter['EU'] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "{'world': 5573338, 'EU': 1408381, 'United States': 909183, 'China': 908048}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(c_sdg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'world': 5288392,\n         'China': 1358934,\n         'United States': 822298,\n         'EU': 1187313})"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'world': 211126, 'China': 44009, 'EU': 48451, 'United States': 31282})"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_inter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                   sdg  percentage_sdg       dt  percentage_dt   inter  \\\nworld          5573338        1.000000  5288392       1.000000  211126   \nEU             1408381        0.252700  1187313       0.224513   48451   \nUnited States   909183        0.163131   822298       0.155491   31282   \nChina           908048        0.162927  1358934       0.256965   44009   \n\n               percentage_inter  \nworld                  1.000000  \nEU                     0.229489  \nUnited States          0.148167  \nChina                  0.208449  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sdg</th>\n      <th>percentage_sdg</th>\n      <th>dt</th>\n      <th>percentage_dt</th>\n      <th>inter</th>\n      <th>percentage_inter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>world</th>\n      <td>5573338</td>\n      <td>1.000000</td>\n      <td>5288392</td>\n      <td>1.000000</td>\n      <td>211126</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>EU</th>\n      <td>1408381</td>\n      <td>0.252700</td>\n      <td>1187313</td>\n      <td>0.224513</td>\n      <td>48451</td>\n      <td>0.229489</td>\n    </tr>\n    <tr>\n      <th>United States</th>\n      <td>909183</td>\n      <td>0.163131</td>\n      <td>822298</td>\n      <td>0.155491</td>\n      <td>31282</td>\n      <td>0.148167</td>\n    </tr>\n    <tr>\n      <th>China</th>\n      <td>908048</td>\n      <td>0.162927</td>\n      <td>1358934</td>\n      <td>0.256965</td>\n      <td>44009</td>\n      <td>0.208449</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sdg_stat = pd.DataFrame.from_dict(c_sdg, orient=\"index\", columns=['sdg'])\n",
    "df_dt_stat = pd.DataFrame.from_dict(c_dt, orient='index', columns=['dt'])\n",
    "df_inter_stat = pd.DataFrame.from_dict(c_inter, orient=\"index\", columns=['inter'])\n",
    "df_sdg_stat.loc[:, 'percentage_sdg'] = df_sdg_stat.loc[:,'sdg'] / df_sdg_stat.loc['world', 'sdg']\n",
    "df_dt_stat.loc[:, 'percentage_dt'] = df_dt_stat.loc[:,'dt'] / df_dt_stat.loc['world', 'dt']\n",
    "df_inter_stat.loc[:, 'percentage_inter'] = df_inter_stat.loc[:,'inter'] / df_inter_stat.loc['world', 'inter']\n",
    "df_stat = pd.concat([df_sdg_stat, df_dt_stat, df_inter_stat], axis=1)\n",
    "df_stat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "df_stat.to_excel('raw_stats_reports_EU.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'WordCloud'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mWordCloud\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'WordCloud'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
